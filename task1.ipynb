{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import spacy\n",
    "from readability import Document\n",
    "import trafilatura\n",
    "from bs4 import BeautifulSoup\n",
    "from html import escape\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def process_webpage_url(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    1) Fetch the webpage HTML via requests.\n",
    "    2) Use Readability to create a simplified HTML, but keep images.\n",
    "    3) Convert that HTML to text for spaCy (NER) using Trafilatura or fallback to BeautifulSoup.\n",
    "    4) Return:\n",
    "       - 'title'\n",
    "       - 'readability_html': cleaned HTML (with images hopefully still in place)\n",
    "       - 'final_text': the text used for NER\n",
    "       - 'entities': list of named entities from spaCy\n",
    "    \"\"\"\n",
    "    # Step 1: Fetch the raw HTML\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch page (status {response.status_code}): {url}\")\n",
    "    html_content = response.text\n",
    "\n",
    "    # Step 2: Readability\n",
    "    # Note: readabilty-lxml does not have a simple \"keep_images=True\" argument, \n",
    "    #       but some images deemed \"important\" should remain. \n",
    "    doc = Document(html_content)\n",
    "    title = doc.short_title() or \"No Title\"\n",
    "\n",
    "    # This is the minimal HTML containing the main content (often includes key images)\n",
    "    readability_html = doc.summary()\n",
    "\n",
    "    # OPTIONAL: convert relative <img> URLs to absolute\n",
    "    # so that images remain valid after saving the HTML locally\n",
    "    soup_cleaned = BeautifulSoup(readability_html, \"html.parser\")\n",
    "    for img_tag in soup_cleaned.find_all(\"img\"):\n",
    "        src = img_tag.get(\"src\")\n",
    "        if src:\n",
    "            # Convert to absolute URL\n",
    "            img_tag[\"src\"] = urljoin(url, src)\n",
    "    # The updated, cleaned HTML that keeps images with absolute links\n",
    "    readability_html_with_images = str(soup_cleaned)\n",
    "\n",
    "    # Step 3: Extract text for spaCy\n",
    "    # We can feed the minimal HTML into Trafilatura for robust text extraction\n",
    "    trafilatura_text = trafilatura.extract(readability_html_with_images)\n",
    "    if not trafilatura_text:\n",
    "        # Fallback to BeautifulSoup if Trafilatura returns None/empty\n",
    "        trafilatura_text = soup_cleaned.get_text(separator=\"\\n\", strip=True)\n",
    "    final_text = trafilatura_text\n",
    "\n",
    "    # Step 4: Named Entity Recognition with spaCy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc_spacy = nlp(final_text)\n",
    "    entities = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc_spacy.ents]\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"readability_html\": readability_html_with_images,  # Cleaned HTML with images\n",
    "        \"final_text\": final_text,  # Plain text for NER\n",
    "        \"entities\": entities,\n",
    "    }\n",
    "\n",
    "def generate_html_output(title: str, cleaned_html: str, entities: list) -> str:\n",
    "    \"\"\"\n",
    "    Creates a final HTML string containing:\n",
    "    - The page title (<title>)\n",
    "    - The cleaned HTML (which may include images)\n",
    "    - A separate Named Entities section appended at the bottom.\n",
    "    \"\"\"\n",
    "    safe_title = escape(title)\n",
    "    \n",
    "    # We'll insert a small block for the named entities after the main content\n",
    "    # Escape each entity text to be safe in HTML\n",
    "    entity_block = \"\"\"<h2>Named Entities</h2>\\n<ul>\\n\"\"\"\n",
    "    if entities:\n",
    "        for ent in entities:\n",
    "            ent_text = escape(ent[\"text\"])\n",
    "            ent_label = escape(ent[\"label\"])\n",
    "            entity_block += f\"  <li>{ent_text} [{ent_label}]</li>\\n\"\n",
    "    else:\n",
    "        entity_block += \"  <li>No entities found.</li>\\n\"\n",
    "    entity_block += \"</ul>\\n\"\n",
    "\n",
    "    # Build the final HTML page:\n",
    "    final_html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>{safe_title}</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>{safe_title}</h1>\n",
    "  {cleaned_html}\n",
    "  {entity_block}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    return final_html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML saved to: extracted_output_with_images.html\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    url_to_process = \"https://hebbarskitchen.com/paneer-ki-sabji-quick-paneer-curry/\"\n",
    "\n",
    "    # 1) Process the webpage\n",
    "    result = process_webpage_url(url_to_process)\n",
    "\n",
    "    # 2) Generate the final HTML that includes images + entity list\n",
    "    html_output = generate_html_output(\n",
    "        title=result[\"title\"],\n",
    "        cleaned_html=result[\"readability_html\"],\n",
    "        entities=result[\"entities\"]\n",
    "    )\n",
    "\n",
    "    # 3) Save that HTML to a file\n",
    "    output_filename = \"extracted_output_with_images.html\"\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_output)\n",
    "    \n",
    "    print(f\"HTML saved to: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
